{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from itertools import combinations, product\n",
    "\n",
    "#sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer, MinMaxScaler\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "#graph\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %config IPCompleter.greedy=True\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib as matplot\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import warnings, os \n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from keras import Sequential\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.layers import *\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# from keras import regularizers\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import xgboost\n",
    "# from mlxtend.classifier import EnsembleVoteClassifier \n",
    "import shap\n",
    "import sklearn.neighbors\n",
    "\n",
    "from deepod.models import PReNet\n",
    "from collections import Counter\n",
    "from modAL.models import ActiveLearner, Committee\n",
    "\n",
    "import copy\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from alipy import ToolBox\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Src IP', 'Dst IP','Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts',\n",
    "    'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min',\n",
    "    'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max',\n",
    "    'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std',\n",
    "    'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std',\n",
    "    'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean',\n",
    "    'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot',\n",
    "    'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min',\n",
    "    'Fwd PSH Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s',\n",
    "    'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean',\n",
    "    'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'PSH Flag Cnt',\n",
    "    'ACK Flag Cnt', 'URG Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg',\n",
    "    'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Subflow Fwd Byts',\n",
    "    'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts',\n",
    "    'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean',\n",
    "    'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std',\n",
    "    'Idle Max', 'Idle Min']\n",
    "def clean_df(df):\n",
    "    # Remove the space before each feature names\n",
    "    df = df[features].copy()\n",
    "    df.columns = df.columns.str.strip()\n",
    "    print('dataset shape', df.shape)\n",
    "    \n",
    "\n",
    "    # This set of feature should have >= 0 values\n",
    "    num = df._get_numeric_data()\n",
    "    num[num < 0] = 0\n",
    "\n",
    "    zero_variance_cols = []\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) == 1:\n",
    "            zero_variance_cols.append(col)\n",
    "    df.drop(zero_variance_cols, axis = 1, inplace = True)\n",
    "    print('zero variance columns', zero_variance_cols, 'dropped')\n",
    "    print('shape after removing zero variance columns:', df.shape)\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "    print(df.isna().any(axis = 1).sum(), 'rows dropped')\n",
    "    df.dropna(inplace = True)\n",
    "    print('shape after removing nan:', df.shape)\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    df.drop_duplicates(inplace = True)\n",
    "    print('shape after dropping duplicates:', df.shape)\n",
    "\n",
    "    column_pairs = [(i, j) for i, j in combinations(df, 2) if df[i].equals(df[j])]\n",
    "    ide_cols = []\n",
    "    for column_pair in column_pairs:\n",
    "        ide_cols.append(column_pair[1])\n",
    "    df.drop(ide_cols, axis = 1, inplace = True)\n",
    "    print('columns which have identical values', column_pairs, 'dropped')\n",
    "    print('shape after removing identical value columns:', df.shape)\n",
    "    return df\n",
    "\n",
    "def sample_df(curr_df, anomaly_rate):\n",
    "    num_benign = len(curr_df.loc[curr_df['Label'] == \"BENIGN\"])\n",
    "    num_attack = len(curr_df) - num_benign\n",
    "    ratio = num_attack / num_benign\n",
    "    \n",
    "    if ratio > anomaly_rate:\n",
    "        sample = anomaly_rate * num_benign / num_attack\n",
    "        sampled_df = pd.concat([curr_df[curr_df['Label'] == 'BENIGN'], \n",
    "                                curr_df[curr_df['Label'] != 'BENIGN'].sample(frac=sample, random_state=42)]) \n",
    "    else:\n",
    "        \n",
    "        sample = (1/anomaly_rate) * num_attack / num_benign\n",
    "        sampled_df = pd.concat([curr_df[curr_df['Label'] != 'BENIGN'], \n",
    "                                curr_df[curr_df['Label'] == 'BENIGN'].sample(frac=sample, random_state=42)]) \n",
    "    \n",
    "    new_ratio = sampled_df.loc[sampled_df[\"Label\"] == \"BENIGN\"].shape[0] / sampled_df.loc[sampled_df[\"Label\"] != \"BENIGN\"].shape[0]\n",
    "    \n",
    "    return sampled_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_20240809091803_ISCX.csv\n",
      "merged_20240809091912_ISCX.csv\n",
      "merged_20240809091837_ISCX.csv\n",
      "merged_20240809091950_ISCX.csv\n",
      "merged_20240809092024_ISCX.csv\n",
      "merged_20240809090239_ISCX.csv\n",
      "merged_20240809090513_ISCX.csv\n",
      "merged_20240809090443_ISCX.csv\n",
      "merged_20240809090412_ISCX.csv\n",
      "merged_20240809090106_ISCX.csv\n",
      "merged_20240809090544_ISCX.csv\n",
      "merged_20240809090035_ISCX.csv\n",
      "merged_20240809090615_ISCX.csv\n",
      "final_merged.csv\n",
      "merged_20240809090137_ISCX.csv\n",
      "merged_20240809090005_ISCX.csv\n",
      "merged_20240809090341_ISCX.csv\n",
      "merged_20240809090310_ISCX.csv\n",
      "merged_20240809090208_ISCX.csv\n",
      "merged_20240813111613_ISCX.csv\n",
      "dataset shape (232661, 63)\n",
      "zero variance columns [] dropped\n",
      "shape after removing zero variance columns: (232661, 63)\n",
      "301 rows dropped\n",
      "shape after removing nan: (232360, 63)\n",
      "shape after dropping duplicates: (166106, 63)\n",
      "columns which have identical values [] dropped\n",
      "shape after removing identical value columns: (166106, 63)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Label\n",
       "dripper    152953\n",
       "BENIGN      47755\n",
       "bonesi      31953\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_csv_path = './Dataset/SimulatedCVE/cicflowmeter_cve/'\n",
    "folder_names = ['dripper/', 'BENIGN/', 'bonesi/']\n",
    "\n",
    "def read_csv():\n",
    "    full_df = pd.DataFrame()\n",
    "    \n",
    "    for folder in folder_names:\n",
    "        csv_file_names = os.listdir(\"Dataset/SimulatedCVE/cicflowmeter_cve/\" + folder)\n",
    "        complete_paths = []\n",
    "        for csv_file_name in csv_file_names:\n",
    "            print(csv_file_name)\n",
    "            complete_paths.append(os.path.join(dataset_csv_path+folder, csv_file_name))\n",
    "        df = pd.concat(map(pd.read_csv, complete_paths), \n",
    "                                ignore_index = True)\n",
    "    \n",
    "        df[\"Label\"] = folder[:-1]\n",
    "        full_df = pd.concat([full_df, df], axis=0, ignore_index=True)\n",
    "    cleaned_df = clean_df(full_df)\n",
    "    return full_df\n",
    "full_df = read_csv()\n",
    "full_df[\"Label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0794cb1710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)  # Set seed for random operations\n",
    "np.random.seed(42)  # Set seed for NumPy operations\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_df = full_df.drop(columns=[\"Flow ID\",\"Src IP\",\"Src Port\",\"Dst IP\",\"Dst Port\",\"Timestamp\"], inplace=False, axis=1).copy()\n",
    "label = flow_df['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D-PCA visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'myenv (Python 3.8.10)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "# # subsample_df = sample_df(normalized_df, 1.0)\n",
    "# subsample_df = normalized_df.copy()\n",
    "# subsample_df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'myenv (Python 3.8.10)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'myenv (Python 3.8.10)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "# # subsample_df = flow_df.groupby('Label').apply(pd.DataFrame.sample, frac = 0.1).reset_index(drop = True)\n",
    "# # subsample_df = pd.concat([subsample_df[subsample_df[\"Label\"] != \"dos_ge_dr\"], subsample_df.groupby('Label').apply(pd.DataFrame.sample, frac=0.1).reset_index(drop=True)])\n",
    "# X = subsample_df.drop(['Label'], axis=1)\n",
    "# y = subsample_df['Label']\n",
    "\n",
    "# # Apply PCA\n",
    "# pca = PCA(n_components=2, random_state=42)\n",
    "# pca_results = pca.fit_transform(X)\n",
    "\n",
    "# # Prepare PCA DataFrame for plotting\n",
    "# pca_df = pd.DataFrame(pca_results, columns=['dimension 1', 'dimension 2'])\n",
    "# pca_df['Label'] = y.values\n",
    "# pca_df['Binary'] = y.apply(lambda x: \"malicious\" if x != 'BENIGN' else 'BENIGN')\n",
    "\n",
    "\n",
    "# # Apply t-SNE\n",
    "# tsne = TSNE(n_components=2, n_jobs=-1, verbose=0, random_state=0, perplexity=20)\n",
    "# tsne_results = tsne.fit_transform(X)\n",
    "\n",
    "# # Prepare t-SNE DataFrame for plotting\n",
    "# tsne_df = pd.DataFrame(tsne_results, columns=['dimension 1', 'dimension 2'])\n",
    "# tsne_df['Label'] = y.values\n",
    "\n",
    "# # Create figure and axes for the subplots\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(20, 10))  # Adjust figsize to fit your needs\n",
    "\n",
    "# # PCA Plot\n",
    "# sns.scatterplot(x='dimension 1', y='dimension 2', hue='Label',\n",
    "#                 palette=sns.color_palette('hls', len(pca_df['Label'].value_counts())),\n",
    "#                 data=pca_df, ax=axes[0])\n",
    "# axes[0].set_title('CICIDS2017 15 Classes PCA Projection')\n",
    "# axes[0].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "# axes[0].set_ylim(-10, 10)\n",
    "\n",
    "# # t-SNE Plot\n",
    "# sns.scatterplot(x='dimension 1', y='dimension 2', hue='Label',\n",
    "#                 palette=sns.color_palette('hls', len(tsne_df['Label'].value_counts())),\n",
    "#                 data=tsne_df, ax=axes[1])\n",
    "# axes[1].set_title('CICIDS2017 15 Classes T-SNE Projection')\n",
    "# axes[1].legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost-ShapValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "1    184906\n",
       "0     47755\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df = flow_df.copy()\n",
    "df['Label'] = df['Label'].apply(lambda x: 0 if x == \"BENIGN\" else 1)\n",
    "df['Label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before (232661, 79)\n",
      "False\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>Fwd Pkt Len Std</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.653354</td>\n",
       "      <td>-0.24415</td>\n",
       "      <td>-0.208093</td>\n",
       "      <td>-0.016581</td>\n",
       "      <td>-0.225957</td>\n",
       "      <td>0.287503</td>\n",
       "      <td>-0.02887</td>\n",
       "      <td>0.192896</td>\n",
       "      <td>0.581033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113087</td>\n",
       "      <td>-0.201698</td>\n",
       "      <td>-0.174232</td>\n",
       "      <td>-0.600189</td>\n",
       "      <td>-0.292625</td>\n",
       "      <td>-0.619362</td>\n",
       "      <td>-0.559182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.651077</td>\n",
       "      <td>-0.24415</td>\n",
       "      <td>-0.208093</td>\n",
       "      <td>-0.017022</td>\n",
       "      <td>-0.225957</td>\n",
       "      <td>0.273313</td>\n",
       "      <td>-0.02887</td>\n",
       "      <td>0.184817</td>\n",
       "      <td>0.558338</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113087</td>\n",
       "      <td>-0.201698</td>\n",
       "      <td>-0.174232</td>\n",
       "      <td>-0.600189</td>\n",
       "      <td>-0.292625</td>\n",
       "      <td>-0.619362</td>\n",
       "      <td>-0.559182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.651076</td>\n",
       "      <td>-0.24415</td>\n",
       "      <td>-0.208093</td>\n",
       "      <td>-0.016911</td>\n",
       "      <td>-0.225957</td>\n",
       "      <td>0.276860</td>\n",
       "      <td>-0.02887</td>\n",
       "      <td>0.186836</td>\n",
       "      <td>0.564012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113087</td>\n",
       "      <td>-0.201698</td>\n",
       "      <td>-0.174232</td>\n",
       "      <td>-0.600189</td>\n",
       "      <td>-0.292625</td>\n",
       "      <td>-0.619362</td>\n",
       "      <td>-0.559182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.651096</td>\n",
       "      <td>-0.24415</td>\n",
       "      <td>-0.208093</td>\n",
       "      <td>-0.014435</td>\n",
       "      <td>-0.225957</td>\n",
       "      <td>0.356676</td>\n",
       "      <td>-0.02887</td>\n",
       "      <td>0.232285</td>\n",
       "      <td>0.691668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113087</td>\n",
       "      <td>-0.201698</td>\n",
       "      <td>-0.174232</td>\n",
       "      <td>-0.600189</td>\n",
       "      <td>-0.292625</td>\n",
       "      <td>-0.619362</td>\n",
       "      <td>-0.559182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.651052</td>\n",
       "      <td>-0.24415</td>\n",
       "      <td>-0.208093</td>\n",
       "      <td>-0.017242</td>\n",
       "      <td>-0.225957</td>\n",
       "      <td>0.266218</td>\n",
       "      <td>-0.02887</td>\n",
       "      <td>0.180777</td>\n",
       "      <td>0.546991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113087</td>\n",
       "      <td>-0.201698</td>\n",
       "      <td>-0.174232</td>\n",
       "      <td>-0.600189</td>\n",
       "      <td>-0.292625</td>\n",
       "      <td>-0.619362</td>\n",
       "      <td>-0.559182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232656</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.210024</td>\n",
       "      <td>-0.22266</td>\n",
       "      <td>-0.099938</td>\n",
       "      <td>-0.035951</td>\n",
       "      <td>-0.224641</td>\n",
       "      <td>-0.336836</td>\n",
       "      <td>-0.02887</td>\n",
       "      <td>-0.162615</td>\n",
       "      <td>-0.417524</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113087</td>\n",
       "      <td>0.984897</td>\n",
       "      <td>1.289192</td>\n",
       "      <td>0.646187</td>\n",
       "      <td>4.405195</td>\n",
       "      <td>1.253535</td>\n",
       "      <td>-0.011967</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232657</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.828802</td>\n",
       "      <td>-0.24415</td>\n",
       "      <td>-0.121569</td>\n",
       "      <td>-0.035951</td>\n",
       "      <td>-0.224641</td>\n",
       "      <td>-0.336836</td>\n",
       "      <td>-0.02887</td>\n",
       "      <td>-0.162615</td>\n",
       "      <td>-0.417524</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113087</td>\n",
       "      <td>0.377653</td>\n",
       "      <td>0.540280</td>\n",
       "      <td>0.392250</td>\n",
       "      <td>3.100454</td>\n",
       "      <td>0.821703</td>\n",
       "      <td>-0.070045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232658</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.815913</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0.289419</td>\n",
       "      <td>0.139259</td>\n",
       "      <td>-0.225957</td>\n",
       "      <td>0.369092</td>\n",
       "      <td>-0.02887</td>\n",
       "      <td>0.215710</td>\n",
       "      <td>0.554727</td>\n",
       "      <td>...</td>\n",
       "      <td>8.558232</td>\n",
       "      <td>4.557952</td>\n",
       "      <td>0.042248</td>\n",
       "      <td>0.310100</td>\n",
       "      <td>2.073020</td>\n",
       "      <td>0.594503</td>\n",
       "      <td>0.004182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232659</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.262889</td>\n",
       "      <td>-0.17968</td>\n",
       "      <td>-0.078307</td>\n",
       "      <td>-0.014050</td>\n",
       "      <td>-0.225957</td>\n",
       "      <td>0.369092</td>\n",
       "      <td>-0.02887</td>\n",
       "      <td>-0.001827</td>\n",
       "      <td>0.296550</td>\n",
       "      <td>...</td>\n",
       "      <td>22.137752</td>\n",
       "      <td>14.844042</td>\n",
       "      <td>3.874391</td>\n",
       "      <td>0.422724</td>\n",
       "      <td>3.594914</td>\n",
       "      <td>0.922367</td>\n",
       "      <td>-0.114993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232660</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.160703</td>\n",
       "      <td>0.03522</td>\n",
       "      <td>0.202895</td>\n",
       "      <td>0.117358</td>\n",
       "      <td>-0.225957</td>\n",
       "      <td>0.369092</td>\n",
       "      <td>-0.02887</td>\n",
       "      <td>0.212557</td>\n",
       "      <td>0.553872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715575</td>\n",
       "      <td>2.910369</td>\n",
       "      <td>3.123597</td>\n",
       "      <td>0.540843</td>\n",
       "      <td>3.897167</td>\n",
       "      <td>1.079196</td>\n",
       "      <td>-0.041167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232661 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Protocol  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  TotLen Fwd Pkts  \\\n",
       "0            0.0      -0.653354      -0.24415     -0.208093        -0.016581   \n",
       "1            0.0      -0.651077      -0.24415     -0.208093        -0.017022   \n",
       "2            0.0      -0.651076      -0.24415     -0.208093        -0.016911   \n",
       "3            0.0      -0.651096      -0.24415     -0.208093        -0.014435   \n",
       "4            0.0      -0.651052      -0.24415     -0.208093        -0.017242   \n",
       "...          ...            ...           ...           ...              ...   \n",
       "232656       0.0       1.210024      -0.22266     -0.099938        -0.035951   \n",
       "232657       0.0       0.828802      -0.24415     -0.121569        -0.035951   \n",
       "232658       0.0       0.815913       0.07820      0.289419         0.139259   \n",
       "232659       0.0       1.262889      -0.17968     -0.078307        -0.014050   \n",
       "232660       0.0       1.160703       0.03522      0.202895         0.117358   \n",
       "\n",
       "        TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  \\\n",
       "0             -0.225957         0.287503         -0.02887          0.192896   \n",
       "1             -0.225957         0.273313         -0.02887          0.184817   \n",
       "2             -0.225957         0.276860         -0.02887          0.186836   \n",
       "3             -0.225957         0.356676         -0.02887          0.232285   \n",
       "4             -0.225957         0.266218         -0.02887          0.180777   \n",
       "...                 ...              ...              ...               ...   \n",
       "232656        -0.224641        -0.336836         -0.02887         -0.162615   \n",
       "232657        -0.224641        -0.336836         -0.02887         -0.162615   \n",
       "232658        -0.225957         0.369092         -0.02887          0.215710   \n",
       "232659        -0.225957         0.369092         -0.02887         -0.001827   \n",
       "232660        -0.225957         0.369092         -0.02887          0.212557   \n",
       "\n",
       "        Fwd Pkt Len Std  ...  Active Std  Active Max  Active Min  Idle Mean  \\\n",
       "0              0.581033  ...   -0.113087   -0.201698   -0.174232  -0.600189   \n",
       "1              0.558338  ...   -0.113087   -0.201698   -0.174232  -0.600189   \n",
       "2              0.564012  ...   -0.113087   -0.201698   -0.174232  -0.600189   \n",
       "3              0.691668  ...   -0.113087   -0.201698   -0.174232  -0.600189   \n",
       "4              0.546991  ...   -0.113087   -0.201698   -0.174232  -0.600189   \n",
       "...                 ...  ...         ...         ...         ...        ...   \n",
       "232656        -0.417524  ...   -0.113087    0.984897    1.289192   0.646187   \n",
       "232657        -0.417524  ...   -0.113087    0.377653    0.540280   0.392250   \n",
       "232658         0.554727  ...    8.558232    4.557952    0.042248   0.310100   \n",
       "232659         0.296550  ...   22.137752   14.844042    3.874391   0.422724   \n",
       "232660         0.553872  ...    0.715575    2.910369    3.123597   0.540843   \n",
       "\n",
       "        Idle Std  Idle Max  Idle Min  Unnamed: 0.1  Unnamed: 0  Label  \n",
       "0      -0.292625 -0.619362 -0.559182           0.0         0.0      1  \n",
       "1      -0.292625 -0.619362 -0.559182           0.0         0.0      1  \n",
       "2      -0.292625 -0.619362 -0.559182           0.0         0.0      1  \n",
       "3      -0.292625 -0.619362 -0.559182           0.0         0.0      1  \n",
       "4      -0.292625 -0.619362 -0.559182           0.0         0.0      1  \n",
       "...          ...       ...       ...           ...         ...    ...  \n",
       "232656  4.405195  1.253535 -0.011967           0.0         0.0      1  \n",
       "232657  3.100454  0.821703 -0.070045           0.0         0.0      1  \n",
       "232658  2.073020  0.594503  0.004182           0.0         0.0      1  \n",
       "232659  3.594914  0.922367 -0.114993           0.0         0.0      1  \n",
       "232660  3.897167  1.079196 -0.041167           0.0         0.0      1  \n",
       "\n",
       "[232661 rows x 80 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (232661, 79)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df['Label'].copy()\n",
    "df.drop(columns='Label', axis=1, inplace=True)\n",
    "print(\"Before\", df.shape)\n",
    "df = df[:]\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)  # Replace inf/-inf with NaN\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "# df = df.loc[:, (df != df.iloc[0]).any()] #Remove features that are constant\n",
    "indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(axis=1)\n",
    "df = df[indices_to_keep]\n",
    "\n",
    "\n",
    "for i in df.columns:\n",
    "    df = df[df[i] != \"Infinity\"]\n",
    "    df = df[df[i] != np.nan]\n",
    "    df = df[df[i] != np.inf]\n",
    "    df = df[df[i] != -np.inf]\n",
    "    df = df[df[i] != \",,\"]\n",
    "    df = df[df[i] != \", ,\"]\n",
    "    \n",
    "print(np.any(np.isnan(df)))\n",
    "print(np.any(np.isfinite(df)))\n",
    "\n",
    "\n",
    "# Last column turn to binary\n",
    "# df.iloc[:, -1] = df.iloc[:, -1].apply(lambda x: 1 if x != 0 else 0).astype(int)\n",
    "#Standardize Dataframe\n",
    "feature_name = list(df.columns)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "feature_name = list(df.columns)\n",
    "normalized_data = scaler.fit_transform(df)\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=feature_name)\n",
    "normalized_df['Label'] = labels.values\n",
    "normalized_df\n",
    "\n",
    "\n",
    "print(\"After\", df.shape)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_df.drop(['Label'],axis=1), normalized_df['Label'], test_size=.20, random_state=42)\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=15, random_state=4022)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=15, random_state=4022)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=15, random_state=4022)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998642705901515\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999049855442292\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Initialize the CART classifier\n",
    "cart_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=15, random_state=4022)\n",
    "cart_classifier.fit(X_train,y_train)\n",
    "model_outputs = cart_classifier.predict(X_test)\n",
    "print(f1_score(model_outputs, y_test))\n",
    "\n",
    "# Train the classifier on the training data\n",
    "\n",
    "model = XGBClassifier(objective='binary:logistic')\n",
    "model.fit(X_train,y_train)\n",
    "model_outputs = model.predict(X_test)\n",
    "pred = model.score(X_test, y_test)\n",
    "print(f1_score(model_outputs, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cic_xgb.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['cic_scaler.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'cic_xgb.joblib')\n",
    "joblib.dump(scaler, 'cic_scaler.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_benign_df = pd.read_csv(os.path.join(dataset_csv_path, \"BENIGN/final_merged.csv\"))\n",
    "# new_benign_df.drop(columns=[\"Unnamed: 0.1\"], inplace=True)\n",
    "# features = ['Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'TotLen Fwd Pkts',\n",
    "#       'TotLen Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Min',\n",
    "#       'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max',\n",
    "#       'Bwd Pkt Len Min', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std',\n",
    "#       'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std',\n",
    "#       'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot', 'Fwd IAT Mean',\n",
    "#       'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Tot',\n",
    "#       'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min',\n",
    "#       'Fwd PSH Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s',\n",
    "#       'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean',\n",
    "#       'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'PSH Flag Cnt',\n",
    "#       'ACK Flag Cnt', 'URG Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg',\n",
    "#       'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Subflow Fwd Byts',\n",
    "#       'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts',\n",
    "#       'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean',\n",
    "#       'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std',\n",
    "#       'Idle Max', 'Idle Min']\n",
    "\n",
    "# X = new_benign_df[features]\n",
    "# X.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "# X.dropna(inplace=True)\n",
    "# X_scaled = scaler.transform(X)\n",
    "\n",
    "# import collections\n",
    "\n",
    "# output = model.predict(X_scaled) \n",
    "# counter = collections.Counter(output)\n",
    "# counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'myenv (Python 3.8.10)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_train)\n",
    "np.shape(shap_values.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'myenv (Python 3.8.10)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "shap.plots.bar(shap_values, max_display=15)\n",
    "plt.show()\n",
    "\n",
    "shap.plots.beeswarm(shap_values, max_display=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_threshold(precision, recall, thresholds):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "        f1_scores[np.isnan(f1_scores)] = 0  # Replace NaN values with 0    \n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "  \n",
    "  \n",
    "def eval_accuracy_from_scores(anomaly_scores, y_test):\n",
    "    fpr, tpr, _ = roc_curve(y_test, anomaly_scores)\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, anomaly_scores)\n",
    "    opt_threshold = get_optimal_threshold(precision, recall, thresholds)\n",
    "    pred = np.where(anomaly_scores > opt_threshold, 1,0)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    conf_matrix = confusion_matrix(y_test, pred)\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    \n",
    "    \n",
    "def set_supervised_label(supervision_rate, anomaly_rate, y):\n",
    "        idx = np.where(y_train == 1)[0]\n",
    "        y = np.zeros_like(y.values)\n",
    "        if supervision_rate == 0:\n",
    "            print(f\"UNSUPERVISED, Sampling Rate = {anomaly_rate}\")\n",
    "            y[idx[:2]] = 1\n",
    "        else:\n",
    "            print(f\"SEMI SUPERVISED, Sampling Rate = {anomaly_rate}, Supervision = {supervision_rate}\")\n",
    "            idx = np.random.choice(idx, size=int(supervision_rate * len(idx)), replace=False)\n",
    "            y[idx] = 1\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "ensemble size: 1\n",
      "epoch  1, training loss: 1.230963, time: 1.9s\n",
      "Start Inference on the training data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<deepod.models.tabular.prenet.PReNet at 0x7f086b2e7ee0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9880\n",
      "[[ 9099   597]\n",
      " [  290 36547]]\n"
     ]
    }
   ],
   "source": [
    "model = PReNet\n",
    "clf = model( device = 'cuda', verbose=1, epochs=1)\n",
    "clf.fit(X=X_train.to_numpy()[:10000], y = y_train[:10000])\n",
    "anomaly_scores = clf.decision_function(X_test.to_numpy())\n",
    "eval_accuracy_from_scores(anomaly_scores, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'myenv (Python 3.8.10)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "# from collections import Counter\n",
    "# model = PReNet\n",
    "# clf = model( device = 'cuda', verbose=1, epochs=1)\n",
    "# y_train_sampled = set_supervised_label(0.02, 0.02, y_train)\n",
    "# counter = Counter(y_train_sampled)\n",
    "# print(counter)\n",
    "# clf.fit(X=X_train.to_numpy(), y = y_train_sampled)\n",
    "# anomaly_scores = clf.decision_function(X_test.to_numpy())\n",
    "# eval_accuracy_from_scores(anomaly_scores, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PReNet' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m clf\u001b[39m.\u001b[39;49mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PReNet' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "clf.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# joblib.dump(clf,\"PReNet_100.joblib\")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m pickle\u001b[39m.\u001b[39;49mdump(clf, \u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mPReNet_100.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# joblib.dump(clf,\"PReNet_100.joblib\")\n",
    "import pickle\n",
    "pickle.dump(clf, open(\"PReNet_100.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'myenv (Python 3.8.10)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
     ]
    }
   ],
   "source": [
    "clf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
